---
title: "Description of Coding for Random Forest PEM "
author: "Will MacKenzie and Gen Perkins"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output:

  #pdf_document:
  #  number_sections: yes
  #  toc: yes
  word_document:
    fig_caption: yes
    #reference_docx: SampleRmarkdown-Template-STYLE.docx
    toc: yes
---


```{r setup, include=FALSE}

# Links for RMarkdown help

# Information about RMarkdown is at: http://rmarkdown.rstudio.com

# Chunk options      https://yihui.name/knitr/options/

# Dealing with word templates and Rmarkdown
#    http://stackoverflow.com/questions/41982700/how-to-properly-number-headings-in-word-from-a-rmarkdown-document
#    http://rmarkdown.rstudio.com/articles_docx.html   
#    http://rmarkdown.rstudio.com/word_document_format.html

# Here we open the libraries needed and source any other code as needed


knitr::opts_chunk$set(echo = TRUE)

library(tidyr)
library(knitr)
library(pander)

#source('http://www.stat.sfu.ca/~cschwarz/Stat-650/Notes/MyPrograms/schwarz.functions.r')


```

## Overview 

The PEM analysis uses a combination of spatial software (ArcMap/QGIS/SAGA), online imagery portals (SentinelHub) and R statistical software to prepare the required data and run the analysis. Field data is currently captured using an mobile application (survey123)

The major analysis is currenlty run using R, which is broken up into four scripts. These are broadly grouped into data preparation (00_Field_Data_Prep.R) and pre-processsing (01_extract_pt_values.R), random forest analysis (02_RandomForest.R) and comparison of model outputs (03_ModelComparison.R). 


### 1) Preparing spatial layers 

Spatial layers are prepared for the areas of interest in raster compatable formats. Identified spatial layers include: AnisotropicHeating, GeneralCurvature, DEM,  MultiResValleyBottomFlatness, Topographic Wetness Index, Slope,Openness_Negative,
Openness_Positive,TerrainRuggedness, TopographicPosition, Biogeoclimatic.Unit, Sentinel 16 band imagery, SPOT5, Lidar related products (Canopy Height Model). 

To assess the influence of scale, all layers are prepared at 25m, 10m and 5m scales. All analysis is to be conducted in BC Albers.



### 2) Random Forest Analysis and Assessment 

The major analysis is currenlty run using R, which is broken up into four scripts which are detailed below


### 00_Field_Data_prep.r 
Format and tidy field data for processing 

- reads in training point data collected using survey123 
- tidy and clean training points to convert to single table with columns of interest. This includes renaming columns, assign rankings to observers, editing text or input typing errors. 
- export a csv to be used as an imput for script 01. 


### 01_extract_pt_values.r

Part 1: Extract values of each spatial layer for all training points 

- read in dataset from script 00 or if other changes completed to file (read in raw data file). 
- extract the point location of all training points (Lat/Long) 
- read in spatial layers prepared above in part 1 and creates a stack of all raster (base layer variables) 
- for each point, extract the asssociated spatial values for every raster/ spatial layer based on location. Seperate outputs are generated for each scale of interest (i.e 5m, 20m, 25m)
- output the data (training points and associated raster values) as tables. 

Part 2: (Optional : Assign mapped BGC information to training points; to be used for furture subseting). 

- read in prep-processed BCG layer (shapefile).
- intersect training point data with BGC layer and compare with field calls of BGC. 
- add TRUE/FALSE where field calls are different to the current mapped BGC layers
- export as a table in csv format 


### 02_Random_Forest.r
This script does the bulk of the analysis using random forest statistics. 

Part 1: 

- Read in the training point file (created in 00_Field_Data_prep,modified in 01_extract_pt_values.r )
- Clean data (remove columns that are not required for analysis, remove data where there is no information on site series)

Selection Point 1: 

- Subset data for the particular model. Theses include the following parameters 
    - BCG, Forest vs Non-Forest, Dominent site series vs other sites series
  
Selection Point 2: 

- In addition the following parameters can also be tested (where data is available) 
    - Field crew members () 
    - Field crew experience rating (1,2,3)
    - If the field point was generated using a Latin Hyper Cube or another means(i.e walking transect) 
    - Certainty awarded to the site series call  (1,2,3,4) 
    - If the site was transitional(1,2,3,4,5,7,Null,Blanks)
    
Selection Point 3:

- Assign a proportion of the data to testing and the training (70/30 split?)

Selection Point 4: 

- Set up the variables (spatial data layers) to include in the model. 
- Define model parameters (response variable, where to output the files, model name, no of trees, how to handle NA values etc.)


Part 3: Create the model and generate model diagnostics

- Run the model (using the R package: Model Map) with the variables and parameters defined above. 
- Generate or add to an existing table outlining a summary of model outputs. These included Out of Bag Error, ommission, commission error rates, PCC. etc. 
- Generate of add to an existing table with ommission/ commision rates per model and per site series. 
These two tables can be used to quickly compare outputs from multiple models as they will continue to add new information with the running of new models. 
- Generates several diagnostic graphs of the model including Out-Of_bag model prediction,  Variable importance map, a histogram, calibration plot, a ROC plot and AUC plot and error rate


Part 4: Use the model output to create a map over the entire Study Site. 

- Use the spatial layers and model prediction to map the predicted Site series across the Study Area.
- Plot the map 
- calculate the frequency of predicted sites series and add to an existing table or generate a new table if none exist. 


### 03_ModelComparison.r

- Read in two maps and create a "difference" map for each comparison of mapped model predictions 


